{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIJO7U23PDpx"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "# Initialize the pipeline with your model\n",
        "pipe = pipeline(\"conversational\", model=\"Qwen/Qwen2-7B-Instruct\")\n",
        "\n",
        "## tested useable model\n",
        "## Qwen/Qwen2-7B-Instruct\n",
        "## AI-MO/NuminaMath-7B-TIR\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## to use converstaion mode in pipeline: need to set it to conversational mode pipeline(\"conversational\", model=\"Qwen/Qwen2-7B-Instruct\") and use Conversation object\n",
        "## conversation object functions:\n",
        "## init: conversation = Conversation()\n",
        "## add message: conversation.add_user_input(\"user message\")\n",
        "## read message/response:  use conversation.generated_responses[-1], which will provide the last response in the response list\n",
        "\n",
        "\n",
        "# Create a new conversation object and start with the first user message\n",
        "\n",
        "conversation = Conversation()\n",
        "\n",
        "conversation.add_user_input(\"Who are you?\")\n",
        "pipe(conversation)\n",
        "print(\"AI:\", conversation.generated_responses[-1])\n",
        "\n",
        "\n",
        "conversation.add_user_input(\"What can you do?\")\n",
        "pipe(conversation)\n",
        "print(\"AI:\", conversation.generated_responses)\n",
        "\n"
      ],
      "metadata": {
        "id": "UGvfmzd0RIep"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}